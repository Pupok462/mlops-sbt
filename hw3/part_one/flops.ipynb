{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-08T16:44:00.282681Z",
     "start_time": "2024-12-08T16:44:00.190445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "GPT5(\n  (transformer): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (fc): Linear(in_features=768, out_features=16, bias=True)\n)"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch2onnx import encode, compute_flops, GPT5\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from thop import profile\n",
    "\n",
    "\n",
    "model_name = 'xd'\n",
    "onnx_filename = 'models/model.onnx'\n",
    "\n",
    "# Tokenize text\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Prepare Model\n",
    "N = 16\n",
    "model = GPT5(N, model_name)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Flops 1 element"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d37482c7d7cf9d67"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слой: fc, FLOPs: 344064.0\n",
      "Слой: attention, FLOPs: 66146304.0\n",
      "Слой: dense, FLOPs: 1179648.0\n",
      "Слой: activation, FLOPs: 0.0\n",
      "Слой: position_embeddings, FLOPs: 0.0\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_mask = encode(tokenizer, \"My name is Clara and I live in Berkeley, California.\")\n",
    "\n",
    "macs, params, layer_info = profile(model, inputs=(input_ids, attention_mask), ret_layer_info=True, verbose=False)\n",
    "total_flops = macs * 2\n",
    "\n",
    "for layer, (layer_macs, _, _) in layer_info.items():\n",
    "    layer_flops = 2 * layer_macs\n",
    "    if layer == 'fc':\n",
    "        print(f\"Слой: {layer}, FLOPs: {layer_flops}\")\n",
    "        \n",
    "trans = model.transformer\n",
    "\n",
    "output = trans.embeddings(input_ids, attention_mask)\n",
    "\n",
    "macs, params, layer_info = profile(trans.encoder.layer[0], inputs=(output,), ret_layer_info=True, verbose=False)\n",
    "total_flops = macs * 2\n",
    "\n",
    "for layer, (layer_macs, _, _) in layer_info.items():\n",
    "    layer_flops = 2 * layer_macs\n",
    "    if layer == 'attention':\n",
    "        print(f\"Слой: {layer}, FLOPs: {layer_flops}\")\n",
    "        \n",
    "\n",
    "output = trans.embeddings(input_ids, attention_mask)\n",
    "output_enc = trans.encoder(output)\n",
    "\n",
    "macs, params, layer_info = profile(trans.pooler, inputs=(output_enc[0],), ret_layer_info=True, verbose=False)\n",
    "total_flops = macs * 2\n",
    "\n",
    "for layer, (layer_macs, _, _) in layer_info.items():\n",
    "    layer_flops = 2 * layer_macs\n",
    "    print(f\"Слой: {layer}, FLOPs: {layer_flops}\")\n",
    "        \n",
    "\n",
    "trans = model.transformer\n",
    "\n",
    "macs, params, layer_info = profile(trans.embeddings, inputs=(input_ids, attention_mask), ret_layer_info=True, verbose=False)\n",
    "total_flops = macs * 2\n",
    "\n",
    "for layer, (layer_macs, _, _) in layer_info.items():\n",
    "    layer_flops = 2 * layer_macs\n",
    "    if layer == 'position_embeddings':\n",
    "        print(f\"Слой: {layer}, FLOPs: {layer_flops}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T14:52:42.183690Z",
     "start_time": "2024-12-08T14:52:42.062961Z"
    }
   },
   "id": "955076c275d427a6",
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Flops 20 element"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f7e86097126ee12"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слой: fc, FLOPs: 6881280.0\n",
      "Слой: attention, FLOPs: 1322926080.0\n",
      "Слой: dense, FLOPs: 23592960.0\n",
      "Слой: activation, FLOPs: 0.0\n",
      "Слой: position_embeddings, FLOPs: 0.0\n"
     ]
    }
   ],
   "source": [
    "message = \"My name is Clara and I live in Berkeley, California.\"\n",
    "batch_size = 20\n",
    "messages = [message] * batch_size  # Список из 10 одинаковых сообщений\n",
    "\n",
    "inputs = tokenizer(messages, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "\n",
    "macs, params, layer_info = profile(model, inputs=(input_ids, attention_mask), ret_layer_info=True, verbose=False)\n",
    "total_flops = macs * 2\n",
    "\n",
    "for layer, (layer_macs, _, _) in layer_info.items():\n",
    "    layer_flops = 2 * layer_macs\n",
    "    if layer == 'fc':\n",
    "        print(f\"Слой: {layer}, FLOPs: {layer_flops}\")\n",
    "        \n",
    "trans = model.transformer\n",
    "\n",
    "output = trans.embeddings(input_ids, attention_mask)\n",
    "\n",
    "macs, params, layer_info = profile(trans.encoder.layer[0], inputs=(output,), ret_layer_info=True, verbose=False)\n",
    "total_flops = macs * 2\n",
    "\n",
    "for layer, (layer_macs, _, _) in layer_info.items():\n",
    "    layer_flops = 2 * layer_macs\n",
    "    if layer == 'attention':\n",
    "        print(f\"Слой: {layer}, FLOPs: {layer_flops}\")\n",
    "        \n",
    "\n",
    "output = trans.embeddings(input_ids, attention_mask)\n",
    "output_enc = trans.encoder(output)\n",
    "\n",
    "macs, params, layer_info = profile(trans.pooler, inputs=(output_enc[0],), ret_layer_info=True, verbose=False)\n",
    "total_flops = macs * 2\n",
    "\n",
    "for layer, (layer_macs, _, _) in layer_info.items():\n",
    "    layer_flops = 2 * layer_macs\n",
    "    print(f\"Слой: {layer}, FLOPs: {layer_flops}\")\n",
    "        \n",
    "\n",
    "trans = model.transformer\n",
    "\n",
    "macs, params, layer_info = profile(trans.embeddings, inputs=(input_ids, attention_mask), ret_layer_info=True, verbose=False)\n",
    "total_flops = macs * 2\n",
    "\n",
    "for layer, (layer_macs, _, _) in layer_info.items():\n",
    "    layer_flops = 2 * layer_macs\n",
    "    if layer == 'position_embeddings':\n",
    "        print(f\"Слой: {layer}, FLOPs: {layer_flops}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T14:52:44.324562Z",
     "start_time": "2024-12-08T14:52:44.125047Z"
    }
   },
   "id": "7ceaaef2b4ad5a88",
   "execution_count": 78
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Память"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddd89bab08553a77"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fc_memory(input_size, output_size, batch_size, dtype=np.float32):\n",
    "    weight_size = input_size * output_size\n",
    "    bias_size = output_size\n",
    "    weights_memory = (weight_size + bias_size) * np.dtype(dtype).itemsize\n",
    "    \n",
    "    return weights_memory * batch_size\n",
    "\n",
    "def attention_memory(batch_size, hidden_size, dtype=np.float32):\n",
    "    dtype_size = np.dtype(dtype).itemsize\n",
    "    weight_memory = (3 * hidden_size**2 + hidden_size**2) * dtype_size\n",
    "    return weight_memory * batch_size\n",
    "\n",
    "def positional_embedding_memory(batch_size, max_seq_len, hidden_size, dtype=np.float32):\n",
    "    dtype_size = np.dtype(dtype).itemsize \n",
    "    embedding_matrix_memory = max_seq_len * hidden_size * dtype_size\n",
    "    return embedding_matrix_memory * batch_size\n",
    "\n",
    "def tanh_memory(batch_size, seq_len, hidden_size, dtype=np.float32):\n",
    "    dtype_size = np.dtype(dtype).itemsize \n",
    "    tensor_memory = batch_size * seq_len * hidden_size * dtype_size\n",
    "    total_memory = 2 * tensor_memory \n",
    "    return total_memory"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T15:16:24.574819Z",
     "start_time": "2024-12-08T15:16:24.564765Z"
    }
   },
   "id": "571dfcdef518063a",
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=768, out_features=16, bias=True)\n",
      "Memory fc batch 1:  49216 bytes\n",
      "Memory fc batch 20:  984320 bytes\n"
     ]
    }
   ],
   "source": [
    "print(model.fc)\n",
    "print('Memory fc batch 1: ', fc_memory(model.fc.in_features, model.fc.out_features, 1), 'bytes')\n",
    "print('Memory fc batch 20: ', fc_memory(model.fc.in_features, model.fc.out_features, 20), 'bytes')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T15:27:17.793067Z",
     "start_time": "2024-12-08T15:27:17.786577Z"
    }
   },
   "id": "e0b7c7e61190d44e",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=768, out_features=768, bias=True)\n",
      "Memory dense batch 1:  2362368 bytes\n",
      "Memory dense batch 20:  47247360 bytes\n"
     ]
    }
   ],
   "source": [
    "print(model.transformer.pooler.dense)\n",
    "print('Memory dense batch 1: ', fc_memory(model.transformer.pooler.dense.in_features, model.transformer.pooler.dense.out_features, 1), 'bytes')\n",
    "print('Memory dense batch 20: ', fc_memory(model.transformer.pooler.dense.in_features, model.transformer.pooler.dense.out_features, 20), 'bytes')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T15:28:26.100361Z",
     "start_time": "2024-12-08T15:28:26.088641Z"
    }
   },
   "id": "18693fb737a55705",
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tanh()\n",
      "Memory tanh batch 1:  6144 bytes\n",
      "Memory tanh batch 20:  122880 bytes\n"
     ]
    }
   ],
   "source": [
    "print(model.transformer.pooler.activation)\n",
    "print('Memory tanh batch 1: ', tanh_memory(1, 1, model.transformer.pooler.dense.out_features), 'bytes')\n",
    "print('Memory tanh batch 20: ', tanh_memory(20, 1, model.transformer.pooler.dense.out_features), 'bytes')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T15:31:59.768229Z",
     "start_time": "2024-12-08T15:31:59.758728Z"
    }
   },
   "id": "3fe049b0affa4952",
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(512, 768)\n",
      "Memory PE batch 1:  1572864 bytes\n",
      "Memory PE batch 20:  31457280 bytes\n"
     ]
    }
   ],
   "source": [
    "print(trans.embeddings.position_embeddings)\n",
    "print('Memory PE batch 1: ', positional_embedding_memory(1, trans.embeddings.position_embeddings.num_embeddings, trans.embeddings.position_embeddings.embedding_dim), 'bytes')\n",
    "print('Memory PE batch 20: ', positional_embedding_memory(20, trans.embeddings.position_embeddings.num_embeddings, trans.embeddings.position_embeddings.embedding_dim), 'bytes')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T15:35:06.546301Z",
     "start_time": "2024-12-08T15:35:06.534836Z"
    }
   },
   "id": "b81e6c5fb605f63c",
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(trans.embeddings.position_embeddings)\n",
    "print('Memory PE batch 1: ', positional_embedding_memory(1, trans.embeddings.position_embeddings.num_embeddings, trans.embeddings.position_embeddings.embedding_dim), 'bytes')\n",
    "print('Memory PE batch 20: ', positional_embedding_memory(20, trans.embeddings.position_embeddings.num_embeddings, trans.embeddings.position_embeddings.embedding_dim), 'bytes')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec3bd8dd36ae6697"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertAttention(\n",
      "  (self): BertSdpaSelfAttention(\n",
      "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (output): BertSelfOutput(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "Memory Attn batch 1:  9437184 bytes\n",
      "Memory Attn batch 20:  188743680 bytes\n"
     ]
    }
   ],
   "source": [
    "print(trans.encoder.layer[0].attention)\n",
    "print('Memory Attn batch 1: ', attention_memory(1, 768), 'bytes')\n",
    "print('Memory Attn batch 20: ', attention_memory(20, 768), 'bytes')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T15:42:42.501006Z",
     "start_time": "2024-12-08T15:42:42.484987Z"
    }
   },
   "id": "8a3a05c534e4cf23",
   "execution_count": 118
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results Table\n",
    "\n",
    "| Layer | FLOPS (1, 20) batch    | Memory (1,20) batch | FLOPS/Memory (1,20) | Limited |\n",
    "|-------|------------------------|---------------------|---------------------|---------|\n",
    "| Proj  | (344064, 6881280)      | (49216, 984320)     | (6.9, 6.9)          | -       |\n",
    "| Dense | (1179648, 23592960)    | (2362368, 47247360) | (0.49, 0.49)        | -       |\n",
    "| Tanh  | (0, 0)                 | (6144, 122880)      | (0, 0)              | -       |\n",
    "| Attn  | (66146304, 1322926080) | (9437184, 188743680)         | (7,  7)             | -       |\n",
    "| PE    | (0, 0)                 | (1572864, 31457280) | (0, 0)              | -       |\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d2f44951080ef3b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "aeb2930a968777ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
